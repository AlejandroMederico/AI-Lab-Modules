from langchain_community.vectorstores import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.schema import Document


def main():
    """Ejemplo mÃ­nimo de buscador semÃ¡ntico con ChromaDB + LangChain."""

    # 1ï¸âƒ£ Modelo de embeddings local (sentenceâ€‘transformers)
    embedding_model = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-mpnet-base-v2"
    )

    # ğŸ§¬Â Mostrar un embedding de ejemplo
    vec = embedding_model.embed_query("Estoy aprendiendo inteligencia artificial")
    print(f"\nğŸ§¬Â Embedding (primeros 10 valores): {vec[:10]}")
    print(f"ğŸ”¢Â DimensiÃ³n: {len(vec)}")  # 384

    # 2ï¸âƒ£Â Documentos a indexar (en producciÃ³n los cargarÃ¡s desde archivos)
    docs = [
        Document(page_content="Estoy aprendiendo inteligencia artificial"),
        Document(page_content="El perro duerme todo el dÃ­a"),
        Document(page_content="Hoy hace calor en Buenos Aires"),
    ]

    # 3ï¸âƒ£Â Crear/cargar la base Chroma persistente
    db = Chroma.from_documents(
        documents=docs,
        embedding=embedding_model,
        persist_directory="./chroma_db_mpnet",  # nuevo folder
        collection_metadata={"hnsw:space": "cosine"},
    )

    # 4ï¸âƒ£Â Consulta semÃ¡ntica
    query = "Estoy estudiando IA"
    results = db.similarity_search_with_relevance_scores(query, k=3)

    print("\nğŸ”Â Resultados con score (1.0 = idÃ©ntico):")
    for doc, score in results:
        print(f"{score:.3f} â†’ {doc.page_content}")


if __name__ == "__main__":
    main()
